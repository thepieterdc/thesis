% !TeX root = ../../thesis.tex

\subsection{\travisci{} build data}
We can answer the first three research questions by analysing data from projects hosted on \travisci{} (\cref{sssec:travisci}). This data has been obtained from two sources.\\

\noindent The first source comprises a database \cite{travisanalysis} of $\SI{35793144}{}$ log files of executed test runs, contributed by Durieux et al. The magnitude of the dataset ($\SI{61.11}{\gibi\byte}$) requires a big data approach to parse these log files. Two straightforward \Gls{mapreduce} pipelines have been created using the Apache Spark\footnote{\url{https://spark.apache.org/}} engine, to provide an answer to the first and second research question respectively.\\

\begin{figure}[htbp!]
	\centering
	\input{assets/tikz/eval-rq1-mapreduce.tex}
	\caption{MapReduce pipeline to find the amount of failed test runs.}
	\label{fig:eval-mapreduce-1}
\end{figure}

\begin{figure}[htbp!]
	\centering
	\input{assets/tikz/eval-rq2-mapreduce.tex}
	\caption{MapReduce pipeline to find the average duration of a successful test run.}
	\label{fig:eval-mapreduce-2}
\end{figure}

\noindent In addition to the first source, another $\SI{3702595}{}$ jobs have been analysed from the \mbox{\emph{TravisTorrent}} project \cite{msr17challenge}. To identify which projects are using \travisci{}, the authors have crawled the \github{} API and examined the build status of every commit to retrieve the run identifier. Subsequently, the \travisci{} API is used to obtain the build information, along with other useful statistics about the project. One of these additional values is the identifier of the previously executed run, which we can use to answer the second research question. Another interesting value is the amount of failed test cases. This value provides an accurate answer to the first research question since it indicates why the test run has failed. Without this information, the test suite might have failed to compile as opposed to an actual failure in the test cases. This dataset has been excluded from the second research question, as the included execution time does not correspond to the actual duration reported on the webpage of \travisci{}. The authors have provided a Google BigQuery\footnote{\url{https://bigquery.cloud.google.com/}} interface to allow querying the dataset more efficiently. \Cref{appendix:travistorrent} contains the corresponding executed queries.