% !TeX root = ../../thesis.tex

\subsection{\travisci{} build data}
We can answer the first three research questions by analysing data from projects hosted on \travisci{} (\cref{sssec:travisci}). This data has been obtained from two sources.\\

\noindent The first source comprises a database \cite{travisanalysis} of $\SI{35793144}{}$ log files of executed test runs, which has been contributed by Durieux et al. The magnitude of the dataset ($\SI{61.11}{\gibi\byte}$) requires a \mbox{big data} approach to parse these log files. Two straightforward \Gls{mapreduce} pipelines (\Cref{fig:eval-mapreduce}) have been created using the Apache Spark\footnote{\url{https://spark.apache.org/}} engine, to provide an answer to the first and second research question.

\begin{figure}[htbp!]
	\centering
	\subfloat[MapReduce pipeline to find the amount of failed test runs.]{%
		\includegraphics[width=\textwidth]{assets/tikz/eval-rq1-mapreduce.tikz}
	}
	\newline
	\subfloat[MapReduce pipeline to find the average duration of a successful test run.]{%
		\includegraphics[width=\textwidth]{assets/tikz/eval-rq2-mapreduce.tikz}
	}
	\caption{MapReduce pipelines for \travisci{} data.}
	\label{fig:eval-mapreduce}
\end{figure}

\noindent In addition to the first source, another $\SI{3702595}{}$ jobs have been analysed from the \mbox{\emph{TravisTorrent}} project \cite{msr17challenge}. To identify which projects are using \travisci{}, the authors have crawled the \github{} API and examined the build status of every commit to retrieve the run identifier.
Subsequently, the \travisci{} API is used to obtain information about both the build, as well as the project itself. This information includes the programming language, the amount of source code lines and the amount of failed test cases. The latter value provides an accurate answer to the first research question since it indicates why the test run has failed. Without this information, the test suite might have failed to compile as opposed to an actual failure in the test cases. Furthermore, the dataset includes the identifier of the previously executed test run, which we can use to answer the third research question. Additionally, the information contains the build duration. This dataset has been excluded from the second research question however, as the included execution time does not correspond to the actual duration reported on the webpage of \travisci{}. The authors have provided a Google BigQuery\footnote{\url{https://bigquery.cloud.google.com/}} interface to allow querying the dataset more efficiently. \Cref{appendix:travistorrent} contains the executed queries.
