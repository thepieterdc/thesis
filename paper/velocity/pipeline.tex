% !TeX root = ../thesis.tex

\section{Pipeline}
This section will elaborate on the individual steps of the pipeline. The steps will be discussed by manually executing the pipeline that has hypothetically been implemented on a Java project. For the sake of simplicity, this explanation will assume a steady-state situation, ensuring the existence of at least one completed run of this project in the database at the controller side.

\subsection{Initialisation}\label{ssec:pipeline-initialisation}
As was explained before, the provided Java implementation of the agent was designed to be used in conjunction with Gradle. In order to integrate \velocity{} into a Gradle project, the build script (\texttt{build.gradle}) should be modified in two places. The first change is to include and apply the plugin in the header of the file. Afterwards, the plugin requires three properties to be configured:
\begin{itemize}
	\item \texttt{base} the path to the Java source files, relative to the location of the build script. This will typically resemble \texttt{src/main/java}.
	
	\item \texttt{repository} the url to the git repository at which the project is hosted. This is required in subsequent steps of the pipeline, to detect which code lines have been changed in the commit currently being analysed.
	
	\item \texttt{server} the url at which the controller can be reached.
\end{itemize}

\noindent \autoref{lst:pipeline-buildgradle} contains a minimal integration of the agent in a Gradle build script, applied to a library for generating random numbers\footnote{\url{https://github.com/thepieterdc/random-java}}}. The controller is hosted at the same host as the agent and is accessible at port \texttt{8080}.

\lstinputlisting[caption=Minimal Gradle buildscript, label=lst:pipeline-buildgradle, language=Groovy]{assets/listings/build.gradle}

\noindent After the project has been configured, the test suite must be executed. For the Gradle agent, this involves executing the built-in \texttt{test} task. This task requires an additional argument to be passed, which is the commit hash of the changeset to prioritise. In every discussed \CI{} system, this commit hash is available as an environment variable.\\

\noindent The first step is for the agent to initiate a new test run in the controller. This is accomplished by sending a \texttt{POST}-request to the \texttt{/runs} endpoint of the controller, which will reply with an identifier. On the controller side, this request will result in a new prioritisation request being enqueued in the database that will asynchronously be processed by the predictor daemon in the next step.

\subsection{Prediction}
The prediction of the test execution order is performed by the predictor daemon. This daemon continuously polls the database to fetch new test runs that need to be predicted. When a new test run is detected, the predictor executes every available prediction algorithm in order to obtain multiple prioritised test sequences. The following algorithms are available:

\paragraph*{AllInOrder} The first algorithm will simply prioritise every test case alphabetically and will be used for for benchmarking purposes in \autoref{chap:evaluation}.

\paragraph*{AllRandom} The second algorithm has also been implemented for benchmarking purposes. This algorithm will ``prioritise'' every test case arbitrarily.

\paragraph*{AffectedRandom} This algorithm will only consider the test cases that cover source code lines which have been modified in the current commit. These test cases will be ordered randomly, followed by the other test cases in the test suite in no particular order.

\paragraph*{GreedyCoverAll} The first of three implementations of the Greedy algorithm (\autoref{ssec:alg-greedy}) will execute the algorithm to prioritise the entire test suite.

\paragraph*{GreedyCoverAffected} As opposed to the previous greedy algorithm, the second Greedy algorithm will only consider test cases covering changed source code lines to be prioritised. After these test cases, the remaining test cases in the test suite will be ordered randomly.

\paragraph*{GreedyTimeAll} Instead of greedily attempting to cover as many lines of the source code using as few tests as possible, this implementation will attempt to execute as many tests as possible, as soon as possible. In other words, this algorithm will prioritise test cases based on their average execution time.

\paragraph*{HGSAll} This algorithm is an implementation of the algorithm presented by Harrold, Gupta and Soffa (\autoref{ssec:alg-hgs}). It is executed for every test case in the test suite.

\paragraph*{HGSAffected} Similar to the \emph{GreedyAffected} algorithm, this algorithm is identical to the previous \emph{HGSAll} algorithm besides that it will only prioritise test cases covering changed source code lines.

\paragraph*{ROCKET} The penultimate algorithm is a straightforward implementation of the pseudocode provided in \autoref{ssec:alg-rocket}.

\paragraph*{Alpha} The final algorithm has been inspired by the other implemented algorithms. \autoref{sec:velocity-alpha} will further elaborate on the details.\\

\noindent Subsequently, the final prioritisation order is determined by applying the meta predictor. Essentially, the meta predictor can be seen as a table which assigns a score to every algorithm, indicating its performance on this codebase. \autoref{ssec:pipeline-postanalysis} will explain later how this score is updated. The predicted order by the algorithm with the highest score is eventually elected by the meta predictor as the final prioritisation order, and saved to the database.

\subsection{Test case execution}
Regarding the agent, the identifier obtained in \autoref{ssec:pipeline-initialisation} is used to poll the controller by sending a \texttt{GET} request to \texttt{/runs/id}, which will reply with the test execution order if this has already been determined. One of the discussed features of Gradle in \autoref{ssec:relatedwork-gradle-junit} was the possibility to execute test cases in a chosen order by adding annotations. However, this feature cannot be used to implement the Java agent, since it only supports ordering test cases within the same test class. In order to facilitate complete control over the order of execution, a custom \texttt{TestProcessor} and \texttt{TestListener} have been implemented.\\

\noindent The \texttt{TestProcessor} is responsible for processing every test class in the classpath and forward it along with configurable options to a delegate processor. The final processor in this chain will eventually perform the actual execution of the test class. Since the delegate processors that are built into Gradle will by default execute every method in the test class, the custom processor needs to work differently. The implemented agent will first store every received test class into a list and load the class to obtain all test cases in the class using reflection. After all classes have been processed, the processor will iterate over the prioritised order. For every test case $t$ in the order, the delegate processor is called with a tuple of the corresponding test class and an options array which excludes every test case except $t$. This will effectively forward the same test class multiple times to the delegate processor, but each time with an option that restricts test execution to the prioritised test case, resulting in the desired behaviour.\\

\noindent Subsequently, the \texttt{TestListener} is a method that is called before and after every invocation of a test case. This listener allows the agent to calculate the duration of every test case, as well as collect the intermediary coverage and save this on a per-test case basis.

\subsection{Post-processing and analysis}\label{ssec:pipeline-postanalysis}
The final step of the pipeline is to provide feedback to the controller, to evaluate the accuracy of the predictions and thereby implementing the fourth design goal of self-improvement. After executing all test cases, the agent sends the test case results, the execution time and the coverage per test case to the controller by issuing a \texttt{POST} request to \texttt{/runs/id/test-results} and \texttt{/runs/id/coverage}.\\

\noindent Upon receiving this data, the controller will update the meta predictor using the following procedure. The meta predictor is only updated if at least one of the test cases has failed, since the objective of \tcp{} is to detect failures as fast as possible, thus every prioritised order is equally good if there are no failures at all. If however a test case did fail, the predicted orders are inspected to calculate the duration until the first failed test case for every order. Subsequently, the average of all these durations is calculated. Finally, the score of every algorithm that predicted a below average duration until the first failure is increased, otherwise it is decreased. This will eventually lead to the most accurate algorithms being preferred in subsequent test runs.