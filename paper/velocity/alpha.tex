% !TeX root = ../thesis.tex

\section{Alpha algorithm}
Besides the algorithms which have been presented in \autoref{sec:relatedwork-algorithms}, an additional algorithm has been implemented: the \emph{Alpha} algorithm. This was constructed by examining the philosophy behind every discussed algorithm and subsequently combining the best ideas into a novel prioritisation algorithm. The specification below will assume the same naming convention as described in \autoref{def:alg-naming}. The pseudocode is provided in Algorithm \ref{alg:alpha}\\

\noindent The algorithm takes the following inputs:
\begin{itemize}
	\item the set of all $n$ test cases: $TS = \{T_1, \dots, T_n\}$
	
	\item the set of $m$ \emph{affected} test cases: $AS = \{A_1, \dots, A_m\} \subseteq TS$. A test case $A$ is considered ``affected'' if any source code line which is covered by $A$ has been modified or removed in the commit that is being predicted.
	
	\item $C$: the set of all lines in the application source code, for which a test case $t \in TS$ exists that covers this line and that has not yet been prioritised. Initially, this set contains every covered source code line.
	
	\item the failure status of every test case, for every past execution out of $k$ executions of that test case: $F = \{F_1, \dots, F_n\}$, where $F_i = \{f_1, \dots, f_k\}$. $F_{tj} = 1$ implies that test case $t$ has failed in execution $j$.
	
	\item the execution time of test case $t \in TS$ for run $r \in [1 \dots k]$, in milliseconds: $D_{tr}$.
\end{itemize}

\noindent The first step of the algorithm is to determine the execution time $E_t$ of every test case $t$. This execution time is calculated as the average of the durations of every successful (i.e.) execution of $t$, since a test case will be prematurely aborted upon the first failed assertion, which introduces bias in the duration timings. In case $t$ has never been executed successfully, the average is computed over every execution of $t$.

\[
E_t = \left\{
\begin{array}{rl}
avg(\{D_{ti} \vert i \in [1 \dots k], F_{ti} = 0\}) & \exists j \in [1 \dots k] : F_{ti} = 0 \\
avg(\{D_{ti} \vert i \in [1 \dots k]\}) & \text{otherwise}
\end{array}
\right\}
\]

\noindent Next, the algorithm executes every affected test case that has also failed at least once in its three previous executions. This reflects the behaviour of a developer attempting to resolve the bug that caused the test case to fail. Specifically executing \emph{affected} failing test cases first is required in case multiple test cases are failing and the developer is resolving these one by one, an idea which was extracted from the ROCKET algorithm (\autoref{ssec:alg-rocket}). In case there are multiple affected failing test cases, the test cases are prioritised by increasing execution time. After every selected test case, $C$ is updated by subtracting the code lines that have been covered by at least one of these test cases.\\

\noindent Afterwards, the same operation is repeated for every failed but unaffected test case, likewise ordered by increasing execution time. Where the previous step helps developers to get fast feedback about whether or not the specific failing test case they were working on has been resolved, this step ensures that other failing test cases are not forgotten and are executed early in the run as well. Similar to the previous step, $C$ is again updated after every prioritised test case.\\

\noindent Research (TODO reference) has indicated that on average, only a small fraction (TODO PERCENTAGE \%) of all test runs will contain failed tests, resulting in the previous two steps not being executed at all. Therefore, the most time should be dedicated to executing test cases that cover affected code lines. More specifically, the next step of the algorithm executes every affected test case, sorted by decreasing cardinality of the intersection between $C$ and the lines which are covered by the test case. Conforming to the prior two steps, $C$ is also updated to reflect the selected test case. As a consequence of these updates, the cardinalities of these intersections change after every update, which will ultimately lead to affected tests not strictly requiring to be executed. This idea has been adopted from the Greedy algorithm \autoref{ssec:alg-greedy}.\\

\noindent In the penultimate step, the previous operation is repeated in an identical fashion for the remaining test cases, similarly ordered by the cardinality of the intersection with the remaining uncovered lines in $C$.\\

\noindent Finally, the algorithm selects every test case which had not yet been prioritised. Notice that these test cases do not contribute to the test coverage, as every test case that would incur additional coverage would have been prioritised already in the previous step. Subsequently, these test cases are actually redundant and are therefore candidates for removal by \tsm{}. However, since this is a prioritisation algorithm, these tests will still be executed and prioritised by increasing execution time.

\begin{algorithm}[h!]
\caption{Alpha algorithm for \tcp{}}
\label{alg:alpha}
\begin{algorithmic}[1]
	\State {\bfseries Input:} Set $TS = \{T_1, \dots, T_n\}$ of all test cases,
	
	Execution time $E$ of every test case,
	
	Failure status $FS$ for each test case over the previous $m$ successive iterations.
	\State {\bfseries Output:} Priority of test cases $P$.
	\State $P \gets array[1 \dots n]$ \Comment{initially $0$}
	\State $MF \gets array[1 \dots m]$
	\ForAll{$i \in 1 \dots m$}
	\State $MF[i] \gets array[1 \dots n]$
	\ForAll{$j \in 1 \dots n$}
	\If{test $T_j$ failed in run $(current - i)$} $MF[i][j] \gets -1$
	\Else{} $MF[i][j] \gets 1$
	\EndIf
	\EndFor
	\EndFor
	\ForAll{$j \in 1 \dots n$}
	\ForAll{$i \in 1 \dots m$}
	\If{$i = 1$} $P[j] \gets P[j] + (MF[i][j] * 0.7)$
	\ElsIf{$i = 2$} $P[j] \gets P[j] + (MF[i][j] * 0.2)$
	\Else{} $P[j] + (MF[i][j] * 0.1)$
	\EndIf
	\EndFor
	\EndFor
	\State $Q \gets \{P[j] \vert j \in 1 \dots n\}$ \Comment{distinct priorities}
	\State $G \gets array[1 \dots Card(Q)]$ \Comment{initially empty sets}
	\ForAll{$j \in 1 \dots n$}
	\State $p \gets P[j]$
	\State $G[p] \gets G[p] \cup \{j\}$
	\EndFor
	\State Sort every group in $G$ based on ascending execution time in $E$.
	\State Sort $P$ according to which group it belongs and its position within that group.
\end{algorithmic}
\end{algorithm}